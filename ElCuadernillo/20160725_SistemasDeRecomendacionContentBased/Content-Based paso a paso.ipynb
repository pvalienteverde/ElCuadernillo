{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./Scripts') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendacion de productos, Content-Based\n",
    "A continuación veremos paso a paso como se puede realizar un sistema de recomendacion basado en el contenido en python. \n",
    "\n",
    "http://www.p.valienteverde.com/sistemas-de-recomendacion-basados-en-el-contenido-content-based/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basado en el Contenido (ContendBased)\n",
    "\n",
    "Por medio de la descripción del producto. Relaciones de tags\n",
    "\n",
    "1. Vectorizacion del contenido, es decir, generar los tags\n",
    "2. Ponderar los tags\n",
    "3. Generar el motor de buscada de los productos similares\n",
    "\n",
    "<img src='imagenes/contect_based.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import ContendBased as CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_wiki.csv</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Gigi_Rigamonti&gt;</td>\n",
       "      <td>Gigi Rigamonti</td>\n",
       "      <td>gigi rigamonti born 8 april 1949 is an italian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Steve_Anderson_(m...</td>\n",
       "      <td>Steve Anderson (musician)</td>\n",
       "      <td>steve anderson was briefly a member of the ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Tenzin_Delek_Rinp...</td>\n",
       "      <td>Tenzin Delek Rinpoche</td>\n",
       "      <td>lithang tulku tenzin delek rinpoche or tenzing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     people_wiki.csv  \\\n",
       "0       <http://dbpedia.org/resource/Gigi_Rigamonti>   \n",
       "1  <http://dbpedia.org/resource/Steve_Anderson_(m...   \n",
       "2  <http://dbpedia.org/resource/Tenzin_Delek_Rinp...   \n",
       "\n",
       "                        name  \\\n",
       "0             Gigi Rigamonti   \n",
       "1  Steve Anderson (musician)   \n",
       "2      Tenzin Delek Rinpoche   \n",
       "\n",
       "                                                text  \n",
       "0  gigi rigamonti born 8 april 1949 is an italian...  \n",
       "1  steve anderson was briefly a member of the ban...  \n",
       "2  lithang tulku tenzin delek rinpoche or tenzing...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"./BD/people_wiki.tar.gz\", compression='gzip')\n",
    "datos.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_wiki.csv</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Elton_John&gt;</td>\n",
       "      <td>Elton John</td>\n",
       "      <td>sir elton hercules john cbe born reginald kenn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             people_wiki.csv        name  \\\n",
       "10  <http://dbpedia.org/resource/Elton_John>  Elton John   \n",
       "\n",
       "                                                 text  \n",
       "10  sir elton hercules john cbe born reginald kenn...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada_elton_john=datos.query('name == \"Elton John\"')\n",
    "entrada_elton_john"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Explorar los tags y su peso\n",
    "1. Primero vamos a vertorizar (extración de los tags) la descripción del producto --> ```CountVectorizer()```\n",
    "2. Calcular la importancia de cada tag en la descripcion del producto --> ```TfidfTransformer()```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Vectorizacion\n",
    "Calculamos los tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vectorizacion = CountVectorizer()\n",
    "bag_of_words= vectorizacion.fit_transform(datos.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peso</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_peso</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          peso\n",
       "tag_peso      \n",
       "the         27\n",
       "in          18\n",
       "and         15\n",
       "of          13\n",
       "has          9\n",
       "he           7\n",
       "john         7\n",
       "on           6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_words_elton_john = vectorizacion.transform(entrada_elton_john.text)\n",
    "CB.mostrar_pesos_tags(bag_words_elton_john,vectorizacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_tf</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.563848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.375898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.271482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>0.187949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.146183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0.146183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>0.125299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tf\n",
       "tag_tf          \n",
       "the     0.563848\n",
       "in      0.375898\n",
       "and     0.313249\n",
       "of      0.271482\n",
       "has     0.187949\n",
       "he      0.146183\n",
       "john    0.146183\n",
       "on      0.125299"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_elton_john_tf=tf_transformer.transform(bag_of_words[entrada_elton_john.index.values])\n",
    "pesos_tf=CB.mostrar_pesos_tags(matrix_elton_john_tf,vectorizacion,descripcion='tf')\n",
    "pesos_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fuck, los tags mas importante no describen los articulos\n",
    "- **SOLUCION**: Normalizar y poderar teniendo en cuenta la frecuencia de cada tag en los demas documenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf-idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_tf-idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.245980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billboard</th>\n",
       "      <td>0.195711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0.189990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elton</th>\n",
       "      <td>0.186575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furnish</th>\n",
       "      <td>0.170638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.164139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.136804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>songwriters</th>\n",
       "      <td>0.120128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tf-idx\n",
       "tag_tf-idx           \n",
       "the          0.245980\n",
       "billboard    0.195711\n",
       "john         0.189990\n",
       "elton        0.186575\n",
       "furnish      0.170638\n",
       "in           0.164139\n",
       "and          0.136804\n",
       "songwriters  0.120128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer(use_idf=True).fit(bag_of_words)\n",
    "matrix_elton_john_tf_idx=tfidf_transformer.transform(bag_of_words[entrada_elton_john.index.values])\n",
    "pesos_tf_idx=CB.mostrar_pesos_tags(matrix_elton_john_tf_idx,vectorizacion,descripcion='tf-idx')\n",
    "pesos_tf_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vamos por el buen camino, vamos a ayudar al algoritmo de dos formas:\n",
    "1. Eliminando las palabras mas comunes --> ```stopwords```\n",
    "2. Eliminado los numeros: Fuera de su contexto pierden todo su significado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pedro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "cachedStopWords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vectorizacion_stop_words     = CountVectorizer(stop_words = cachedStopWords, token_pattern='(?u)\\\\b[a-zA-Z]\\\\w\\\\w+\\\\b')\n",
    "bag_of_words_stop_words      = vectorizacion_stop_words.fit_transform(datos.text)\n",
    "tfidf_transformer_stop_words = TfidfTransformer(use_idf=True).fit(bag_of_words_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idx_filtrado</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_tf_idx_filtrado</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>billboard</th>\n",
       "      <td>0.230409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0.223674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elton</th>\n",
       "      <td>0.219654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furnish</th>\n",
       "      <td>0.200891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>songwriters</th>\n",
       "      <td>0.141425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award</th>\n",
       "      <td>0.141251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.140106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aids</th>\n",
       "      <td>0.132142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tf_idx_filtrado\n",
       "tag_tf_idx_filtrado                 \n",
       "billboard                   0.230409\n",
       "john                        0.223674\n",
       "elton                       0.219654\n",
       "furnish                     0.200891\n",
       "songwriters                 0.141425\n",
       "award                       0.141251\n",
       "top                         0.140106\n",
       "aids                        0.132142"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_elton_john_tf_idx_stop_words=tfidf_transformer_stop_words.transform(bag_of_words_stop_words[entrada_elton_john.index.values])\n",
    "pesos_tf_idx_filtrado=CB.mostrar_pesos_tags(matrix_elton_john_tf_idx_stop_words,vectorizacion_stop_words,descripcion='tf_idx_filtrado')\n",
    "pesos_tf_idx_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Comparativa de las mejoras realizadas\n",
    "- **tf**: Poderamos y normalizados los tags de cada articulo\n",
    "- **tf-idx**: Poderamos y normalizados los tags de cada articulo teniendo en cuenta la frecuencia de cada tag en los demas articulos\n",
    "- **tf_idx_filtrado**: Eliminamos las palabras mas comunes y los numeros a tf-idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_tf</th>\n",
       "      <th>tf</th>\n",
       "      <th>tag_tf-idx</th>\n",
       "      <th>tf-idx</th>\n",
       "      <th>tag_tf_idx_filtrado</th>\n",
       "      <th>tf_idx_filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>0.563848</td>\n",
       "      <td>the</td>\n",
       "      <td>0.245980</td>\n",
       "      <td>billboard</td>\n",
       "      <td>0.230409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>0.375898</td>\n",
       "      <td>billboard</td>\n",
       "      <td>0.195711</td>\n",
       "      <td>john</td>\n",
       "      <td>0.223674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>0.313249</td>\n",
       "      <td>john</td>\n",
       "      <td>0.189990</td>\n",
       "      <td>elton</td>\n",
       "      <td>0.219654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>0.271482</td>\n",
       "      <td>elton</td>\n",
       "      <td>0.186575</td>\n",
       "      <td>furnish</td>\n",
       "      <td>0.200891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>has</td>\n",
       "      <td>0.187949</td>\n",
       "      <td>furnish</td>\n",
       "      <td>0.170638</td>\n",
       "      <td>songwriters</td>\n",
       "      <td>0.141425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he</td>\n",
       "      <td>0.146183</td>\n",
       "      <td>in</td>\n",
       "      <td>0.164139</td>\n",
       "      <td>award</td>\n",
       "      <td>0.141251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>john</td>\n",
       "      <td>0.146183</td>\n",
       "      <td>and</td>\n",
       "      <td>0.136804</td>\n",
       "      <td>top</td>\n",
       "      <td>0.140106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>on</td>\n",
       "      <td>0.125299</td>\n",
       "      <td>songwriters</td>\n",
       "      <td>0.120128</td>\n",
       "      <td>aids</td>\n",
       "      <td>0.132142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag_tf        tf   tag_tf-idx    tf-idx tag_tf_idx_filtrado  tf_idx_filtrado\n",
       "0    the  0.563848          the  0.245980           billboard         0.230409\n",
       "1     in  0.375898    billboard  0.195711                john         0.223674\n",
       "2    and  0.313249         john  0.189990               elton         0.219654\n",
       "3     of  0.271482        elton  0.186575             furnish         0.200891\n",
       "4    has  0.187949      furnish  0.170638         songwriters         0.141425\n",
       "5     he  0.146183           in  0.164139               award         0.141251\n",
       "6   john  0.146183          and  0.136804                 top         0.140106\n",
       "7     on  0.125299  songwriters  0.120128                aids         0.132142"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pesos_tf.reset_index(level=0),pesos_tf_idx.reset_index(level=0),pesos_tf_idx_filtrado.reset_index(level=0)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Forma rapida\n",
    "Todos los pasos anteriores se puede simplificar por medio de un metodo de sklearn que los agrutina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', '...aven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'],\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b[a-zA-Z]\\\\w\\\\w+\\\\b', tokenizer=None,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer( stop_words=cachedStopWords, token_pattern='(?u)\\\\b[a-zA-Z]\\\\w\\\\w+\\\\b')\n",
    "tfidf_vectorizer.fit(datos.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peso</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_peso</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>billboard</th>\n",
       "      <td>0.230409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>john</th>\n",
       "      <td>0.223674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elton</th>\n",
       "      <td>0.219654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furnish</th>\n",
       "      <td>0.200891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>songwriters</th>\n",
       "      <td>0.141425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award</th>\n",
       "      <td>0.141251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.140106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aids</th>\n",
       "      <td>0.132142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 peso\n",
       "tag_peso             \n",
       "billboard    0.230409\n",
       "john         0.223674\n",
       "elton        0.219654\n",
       "furnish      0.200891\n",
       "songwriters  0.141425\n",
       "award        0.141251\n",
       "top          0.140106\n",
       "aids         0.132142"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CB.mostrar_pesos_tags(tfidf_vectorizer.transform(entrada_elton_john.text),tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediccion\n",
    "Una vez que ya hemos extraidos los tags de los productos, buscamos por similitud los mas parecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vecinos            = NearestNeighbors(n_neighbors=5,metric='cosine',algorithm='brute')\n",
    "datos_por_tags     = tfidf_vectorizer.transform(datos.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecinos.fit(datos_por_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con nuestro motor de recomendacion creado, podemos utilizarlo como un buscador de articulos. Como se verá, de los 5 actores propuestos, 4 de ellos al menos ha ganado un oscar !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_wiki.csv</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Al_Pacino&gt;</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>alfredo james al pacino ptino born april 25 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Ethan_Hawke&gt;</td>\n",
       "      <td>Ethan Hawke</td>\n",
       "      <td>ethan green hawke born november 6 1970 is an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12795</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Ralph_Fiennes&gt;</td>\n",
       "      <td>Ralph Fiennes</td>\n",
       "      <td>ralph nathaniel twisletonwykehamfiennes ref fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Daniel_Day-Lewis&gt;</td>\n",
       "      <td>Daniel Day-Lewis</td>\n",
       "      <td>sir daniel michael blake daylewis kt born 29 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4677</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Michael_Keaton&gt;</td>\n",
       "      <td>Michael Keaton</td>\n",
       "      <td>michael john douglas born september 5 1951 bet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      people_wiki.csv              name  \\\n",
       "185           <http://dbpedia.org/resource/Al_Pacino>         Al Pacino   \n",
       "10267       <http://dbpedia.org/resource/Ethan_Hawke>       Ethan Hawke   \n",
       "12795     <http://dbpedia.org/resource/Ralph_Fiennes>     Ralph Fiennes   \n",
       "3474   <http://dbpedia.org/resource/Daniel_Day-Lewis>  Daniel Day-Lewis   \n",
       "4677     <http://dbpedia.org/resource/Michael_Keaton>    Michael Keaton   \n",
       "\n",
       "                                                    text  \n",
       "185    alfredo james al pacino ptino born april 25 19...  \n",
       "10267  ethan green hawke born november 6 1970 is an a...  \n",
       "12795  ralph nathaniel twisletonwykehamfiennes ref fa...  \n",
       "3474   sir daniel michael blake daylewis kt born 29 a...  \n",
       "4677   michael john douglas born september 5 1951 bet...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buscador  = tfidf_vectorizer.transform(['Award Actor Oscar'])\n",
    "distancia,indices       = vecinos.kneighbors(buscador)\n",
    "datos.iloc[indices[0],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Veamos que famosos nos relaciona con Al Pacino..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_wiki.csv</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Al_Pacino&gt;</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>alfredo james al pacino ptino born april 25 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12795</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Ralph_Fiennes&gt;</td>\n",
       "      <td>Ralph Fiennes</td>\n",
       "      <td>ralph nathaniel twisletonwykehamfiennes ref fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Ethan_Hawke&gt;</td>\n",
       "      <td>Ethan Hawke</td>\n",
       "      <td>ethan green hawke born november 6 1970 is an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Daniel_Day-Lewis&gt;</td>\n",
       "      <td>Daniel Day-Lewis</td>\n",
       "      <td>sir daniel michael blake daylewis kt born 29 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Jeff_Daniels&gt;</td>\n",
       "      <td>Jeff Daniels</td>\n",
       "      <td>jeffrey warren jeff daniels born february 19 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      people_wiki.csv              name  \\\n",
       "185           <http://dbpedia.org/resource/Al_Pacino>         Al Pacino   \n",
       "12795     <http://dbpedia.org/resource/Ralph_Fiennes>     Ralph Fiennes   \n",
       "10267       <http://dbpedia.org/resource/Ethan_Hawke>       Ethan Hawke   \n",
       "3474   <http://dbpedia.org/resource/Daniel_Day-Lewis>  Daniel Day-Lewis   \n",
       "460        <http://dbpedia.org/resource/Jeff_Daniels>      Jeff Daniels   \n",
       "\n",
       "                                                    text  \n",
       "185    alfredo james al pacino ptino born april 25 19...  \n",
       "12795  ralph nathaniel twisletonwykehamfiennes ref fa...  \n",
       "10267  ethan green hawke born november 6 1970 is an a...  \n",
       "3474   sir daniel michael blake daylewis kt born 29 a...  \n",
       "460    jeffrey warren jeff daniels born february 19 1...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al_pacino_vectorizado  = tfidf_vectorizer.transform(datos.query('name == \"Al Pacino\"').text)\n",
    "distancia,indices       = vecinos.kneighbors(al_pacino_vectorizado)\n",
    "datos.iloc[indices[0],:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
